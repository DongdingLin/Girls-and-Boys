{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 添加库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys,warnings,time,pickle\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier,GradientBoostingClassifier\n",
    "from sklearn import metrics,svm\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from xgboost import plot_importance,XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier,LGBMRegressor\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feather_path_list = list([None for i in range(110)])\n",
    "feather_path_list[0] = \"./DataSet/SpiltToNumeric/numeric_data.csv\"\n",
    "feather_path_list[1] = \"./DataSet/DealAllString/time_0_factorize.csv\"\n",
    "feather_path_list[2] = \"./DataSet/DealAllString/time_1_factorize.csv\"\n",
    "feather_path_list[3] = \"./DataSet/DealAllString/time_2_factorize.csv\"\n",
    "feather_path_list[4] = \"./DataSet/DealAllString/Col0-3.csv\"\n",
    "feather_path_list[5] = \"./DataSet/DealAllString/Col4half.csv\"\n",
    "feather_path_list[6] = \"./DataSet/DealAllString/Col4half2.csv\"\n",
    "feather_path_list[7] = \"./DataSet/DealAllString/Col5half.csv\"\n",
    "feather_path_list[8] = \"./DataSet/DealAllString/Col5half2.csv\"\n",
    "feather_path_list[9] = \"./DataSet/DealAllString/Col6.csv\"\n",
    "feather_path_list[10] = \"./DataSet/DealAllString/Col7.csv\"\n",
    "feather_path_list[11] = \"./DataSet/DealAllString/Col8half.csv\"\n",
    "feather_path_list[12] = \"./DataSet/DealAllString/Col8half2.csv\"\n",
    "feather_path_list[13] = \"./DataSet/DealAllString/Col9half.csv\"\n",
    "feather_path_list[14] = \"./DataSet/DealAllString/Col9half2.csv\"\n",
    "feather_path_list[15] = \"./DataSet/DealAllString/Col10half.csv\"\n",
    "feather_path_list[16] = \"./DataSet/DealAllString/Col10half2.csv\"\n",
    "feather_path_list[17] = \"./DataSet/DealAllString/Col11half.csv\"\n",
    "feather_path_list[18] = \"./DataSet/DealAllString/Col11half2.csv\"\n",
    "feather_path_list[19] = \"./DataSet/DealAllString/Col12half.csv\"\n",
    "feather_path_list[20] = \"./DataSet/DealAllString/Col12half2.csv\"\n",
    "feather_path_list[21] = \"./DataSet/DealAllString/Col13half.csv\"\n",
    "feather_path_list[22] = \"./DataSet/DealAllString/Col13half2.csv\"\n",
    "feather_path_list[23] = \"./DataSet/DealAllString/Col14half.csv\"\n",
    "feather_path_list[24] = \"./DataSet/DealAllString/Col14half2.csv\"\n",
    "feather_path_list[25] = \"./DataSet/DealAllString/Col15half.csv\"\n",
    "feather_path_list[26] = \"./DataSet/DealAllString/Col15half2.csv\"\n",
    "feather_path_list[27] = \"./DataSet/DealAllString/Col16half.csv\"\n",
    "feather_path_list[28] = \"./DataSet/DealAllString/Col16half2.csv\"\n",
    "feather_path_list[29] = \"./DataSet/DealAllString/Col17half.csv\"\n",
    "feather_path_list[30] = \"./DataSet/DealAllString/Col17half2.csv\"\n",
    "feather_path_list[31] = \"./DataSet/DealAllString/Col18half.csv\"\n",
    "feather_path_list[32] = \"./DataSet/DealAllString/Col18half2.csv\"\n",
    "feather_path_list[33] = \"./DataSet/DealAllString/Col19half.csv\"\n",
    "feather_path_list[34] = \"./DataSet/DealAllString/Col19half2.csv\"\n",
    "feather_path_list[35] = \"./DataSet/DealAllString/Col20half.csv\"\n",
    "feather_path_list[36] = \"./DataSet/DealAllString/Col20half2.csv\"\n",
    "feather_path_list[37] = \"./DataSet/DealAllString/Col21half.csv\"\n",
    "feather_path_list[38] = \"./DataSet/DealAllString/Col21half2.csv\"\n",
    "feather_path_list[39] = \"./DataSet/DealAllString/Col22half.csv\"\n",
    "feather_path_list[40] = \"./DataSet/DealAllString/Col22half2.csv\"\n",
    "feather_path_list[41] = \"./DataSet/DealAllString/Col23half.csv\"\n",
    "feather_path_list[42] = \"./DataSet/DealAllString/Col23half2.csv\"\n",
    "feather_path_list[43] = \"./DataSet/DealAllString/Col24quarter1.csv\"\n",
    "feather_path_list[44] = \"./DataSet/DealAllString/Col24quarter2.csv\"\n",
    "feather_path_list[45] = \"./DataSet/DealAllString/Col24quarter3.csv\"\n",
    "feather_path_list[46] = \"./DataSet/DealAllString/Col24quarter4.csv\"\n",
    "feather_path_list[47] = \"./DataSet/DealAllString/Col25quarter1.csv\"\n",
    "feather_path_list[48] = \"./DataSet/DealAllString/Col25quarter2.csv\"\n",
    "feather_path_list[49] = \"./DataSet/DealAllString/Col25quarter3.csv\"\n",
    "feather_path_list[50] = \"./DataSet/DealAllString/Col25quarter4.csv\"\n",
    "feather_path_list[51] = \"./DataSet/DealAllString/All_Factorize.csv\"\n",
    "feather_path_list[52] = \"./DataSet/TrickData/trick1-4.csv\"\n",
    "feather_path_list[53] = \"./DataSet/TrickData/trick5-8.csv\"\n",
    "feather_path_list[54] = \"./DataSet/TrickData/trick9-12.csv\"\n",
    "feather_path_list[55] = \"./DataSet/TrickData/trick13-16.csv\"\n",
    "feather_path_list[56] = \"./DataSet/TrickData/trick17-20.csv\"\n",
    "# feather_path_list[57] = \"./DataSet/TrickData/trick24,26,28,30min.csv\"\n",
    "feather_path_list[58] = \"./DataSet/TrickData/trick24,26,28,30mean.csv\"\n",
    "# feather_path_list[59] = \"./DataSet/TrickData/trick25,27,29,31min.csv\"\n",
    "feather_path_list[60] = \"./DataSet/TrickData/trick25,27,29,31mean.csv\"\n",
    "# feather_path_list[61] = \"./DataSet/TrickData/trick32,35,38,41,44,47min.csv\"\n",
    "feather_path_list[62] = \"./DataSet/TrickData/trick32,35,38,41,44,47mean.csv\"\n",
    "# feather_path_list[63] = \"./DataSet/TrickData/trick33,36,39,42,45,48min.csv\"\n",
    "feather_path_list[64] = \"./DataSet/TrickData/trick33,36,39,42,45,48mean.csv\"\n",
    "# feather_path_list[65] = \"./DataSet/TrickData/trick34,37,40,43,46,49min.csv\"\n",
    "feather_path_list[66] = \"./DataSet/TrickData/trick34,37,40,43,46,49mean.csv\"\n",
    "# feather_path_list[67] = \"./DataSet/TrickData/trick59,62,66,70,74,78,81min.csv\"\n",
    "feather_path_list[68] = \"./DataSet/TrickData/trick59,62,66,70,74,78,81mean.csv\"\n",
    "# feather_path_list[69] = \"./DataSet/TrickData/trick60,63,67,71,75,79,82min.csv\"\n",
    "feather_path_list[70] = \"./DataSet/TrickData/trick60,63,67,71,75,79,82mean.csv\"\n",
    "# feather_path_list[72] = \"./DataSet/TrickData/trick61,64,65,69,73,77,80,84min.csv\"\n",
    "feather_path_list[73] = \"./DataSet/TrickData/trick61,64,65,69,73,77,80,84mean.csv\"\n",
    "# feather_path_list[74] = \"./DataSet/TrickData/trick68,72,76,83min.csv\"\n",
    "feather_path_list[75] = \"./DataSet/TrickData/trick68,72,76,83mean.csv\"\n",
    "# feather_path_list[76] = \"./DataSet/TrickData/trick85,86,87min.csv\"\n",
    "feather_path_list[77] = \"./DataSet/TrickData/trick85,86,87mean.csv\"\n",
    "# feather_path_list[78] = \"./DataSet/TrickData/trick94,95,96,97,98,99,100min.csv\"\n",
    "feather_path_list[79] = \"./DataSet/TrickData/trick94,95,96,97,98,99,100mean.csv\"\n",
    "feather_path_list[80] = \"./DataSet/TrickData/trick103,105,108,110.csv\"\n",
    "feather_path_list[81] = \"./DataSet/TrickData/trick106,111mean.csv\"\n",
    "feather_path_list[82] = \"./DataSet/TrickData/trick113,115mean.csv\"\n",
    "feather_path_list[83] = \"./DataSet/TrickData/trick118,121mean.csv\"\n",
    "feather_path_list[84] = \"./DataSet/TrickData/trick123,125mean.csv\"\n",
    "feather_path_list[85] = \"./DataSet/TrickData/trick127,129mean.csv\"\n",
    "feather_path_list[86] = \"./DataSet/TrickData/trick131,133mean.csv\"\n",
    "feather_path_list[87] = \"./DataSet/TrickData/trick135,137mean.csv\"\n",
    "feather_path_list[88] = \"./DataSet/TrickData/trick140,142mean.csv\"\n",
    "feather_path_list[89] = \"./DataSet/TrickData/trick145,147mean.csv\"\n",
    "feather_path_list[90] = \"./DataSet/TrickData/trick149,151mean.csv\"\n",
    "feather_path_list[91] = \"./DataSet/TrickData/trick153,155mean.csv\"\n",
    "feather_path_list[92] = \"./DataSet/TrickData/trick156,157.csv\"\n",
    "# feather_path_list[93] = \"./DataSet/TrickData/trick161,162,163,164min.csv\"\n",
    "feather_path_list[94] = \"./DataSet/TrickData/trick161,162,163,164mean.csv\"\n",
    "# feather_path_list[95] = \"./DataSet/TrickData/trick165,166,167,168,169,min.csv\"\n",
    "feather_path_list[96] = \"./DataSet/TrickData/trick165,166,167,168,169mean.csv\"\n",
    "# feather_path_list[97] = \"./DataSet/TrickData/trick170,171,172,173,174,175,176,177,178min.csv\"\n",
    "feather_path_list[98] = \"./DataSet/TrickData/trick170,171,172,173,174,175,176,177,178mean.csv\"\n",
    "# feather_path_list[99] = \"./DataSet/TrickData/trick179,180,181,186min.csv\"\n",
    "feather_path_list[100] = \"./DataSet/TrickData/trick179,180,181,186mean.csv\"\n",
    "# feather_path_list[101] = \"./DataSet/TrickData/trick182,183,184,185min.csv\"\n",
    "feather_path_list[102] = \"./DataSet/TrickData/trick182,183,184,185mean.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feather_list = list()\n",
    "for i in feather_path_list:\n",
    "    if i == None:\n",
    "        continue\n",
    "    temp = pd.read_csv(i, header=None)\n",
    "    feather_list.append(temp)\n",
    "all_data = pd.concat(feather_list,axis=1)\n",
    "all_data.columns = range(len(all_data.columns))\n",
    "train_label = pd.read_csv(\"./DataSet/Standardlize/train_label.csv\",header=None)\n",
    "train_count = len(train_label)\n",
    "train_data = all_data.iloc[:train_count, :]\n",
    "test_data = all_data.iloc[train_count:, :]\n",
    "X = train_data.values\n",
    "y = train_label.replace(-1,0).values.squeeze()\n",
    "test = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stacking第一层\n",
    "def model_fit_pred(model, train_set, train_label, vali_set, vali_label, test_set):\n",
    "    if model == 'RF':\n",
    "        RF_model = RandomForestClassifier(bootstrap=True,n_jobs=32,max_depth=12,n_estimators=170)\n",
    "        RF_model.fit(train_set, train_label)\n",
    "        if RF_model.predict_proba(vali_set).shape[1] == 2:\n",
    "            train_pred = RF_model.predict_proba(vali_set)[:,1]\n",
    "        else:\n",
    "            train_pred = RF_model.predict_proba(vali_set)[:,0]\n",
    "            \n",
    "        if RF_model.predict_proba(test_set).shape[1] == 2:\n",
    "            test_pred = RF_model.predict_proba(test_set)[:,1]\n",
    "        else:\n",
    "            test_pred = RF_model.predict_proba(test_set)[:,0]\n",
    "    elif model == 'LGBM1':\n",
    "        lgb_model = LGBMClassifier(\n",
    "        num_leaves=128, boosting_type='gbdt', learning_rate=0.01, n_estimators=1050, subsample_for_bin=200,\n",
    "        objective='binary', min_split_gain=0., min_child_weight=1e-5, min_child_samples=10,subsample=0.5, \n",
    "        subsample_freq=1, colsample_bytree=.9, reg_alpha=0.8, reg_lambda=0.8, n_jobs=32, silent=True,random_state=1377)\n",
    "        lgb_model.fit(train_set, train_label)\n",
    "        train_pred = lgb_model.predict_proba(vali_set)[:,1]\n",
    "        test_pred = lgb_model.predict_proba(test_set)[:,1]\n",
    "    elif model == 'LGBM2':\n",
    "        lgb_model = LGBMClassifier(\n",
    "        num_leaves=128, boosting_type='gbdt', learning_rate=0.01, n_estimators=1100, subsample_for_bin=200,\n",
    "        objective='binary', min_split_gain=0., min_child_weight=1e-5, min_child_samples=10,subsample=0.5, \n",
    "        subsample_freq=1, colsample_bytree=.9, reg_alpha=0.5, reg_lambda=0.8, n_jobs=32, silent=True,random_state=1377)\n",
    "        lgb_model.fit(train_set, train_label)\n",
    "        train_pred = lgb_model.predict_proba(vali_set)[:,1]\n",
    "        test_pred = lgb_model.predict_proba(test_set)[:,1]\n",
    "    elif model == 'LGBM3':\n",
    "        lgb_model = LGBMClassifier(\n",
    "        num_leaves=128, boosting_type='gbdt', learning_rate=0.01, n_estimators=1200, subsample_for_bin=200,\n",
    "        objective='binary', min_split_gain=0., min_child_weight=1e-5, min_child_samples=15,subsample=0.5, \n",
    "        subsample_freq=1, colsample_bytree=.9, reg_alpha=0.5, reg_lambda=0.8, n_jobs=32, silent=True,random_state=1377)\n",
    "        lgb_model.fit(train_set, train_label)\n",
    "        train_pred = lgb_model.predict_proba(vali_set)[:,1]\n",
    "        test_pred = lgb_model.predict_proba(test_set)[:,1]\n",
    "    elif model == 'LGBM4':\n",
    "        lgb_model = LGBMClassifier(\n",
    "        num_leaves=128, boosting_type='gbdt', learning_rate=0.01, n_estimators=1200, subsample_for_bin=200,\n",
    "        objective='binary', min_split_gain=0., min_child_weight=1e-2, min_child_samples=5,subsample=0.5, \n",
    "        subsample_freq=1, colsample_bytree=.8, reg_alpha=0.6, reg_lambda=0.8, n_jobs=32, silent=True,random_state=1377)\n",
    "        lgb_model.fit(train_set, train_label)\n",
    "        train_pred = lgb_model.predict_proba(vali_set)[:,1]\n",
    "        test_pred = lgb_model.predict_proba(test_set)[:,1]\n",
    "    return train_pred, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stacking第二层\n",
    "def stacking(model_list, X, y, test_set):\n",
    "    # First level learning model\n",
    "    # Create new data\n",
    "    new_train_matrix = list()\n",
    "    new_test_matrix  = list()\n",
    "    \n",
    "    for model in model_list:\n",
    "        skf = StratifiedKFold(n_splits=5,shuffle=True, random_state=1377)\n",
    "        new_train_col = np.zeros(len(y))\n",
    "        new_test_col = np.zeros(len(test_set))\n",
    "        \n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_vali = X[train_index], X[test_index]\n",
    "            y_train, y_vali = y[train_index], y[test_index]\n",
    "            \n",
    "            print (model)\n",
    "            train_pred, test_pred = model_fit_pred(model, X_train, y_train, X_vali, y_vali, test_set)\n",
    "            new_train_col[test_index] = train_pred\n",
    "            new_test_col = new_test_col+test_pred\n",
    "            \n",
    "        new_test_col = new_test_col/5\n",
    "        new_train_matrix.append(new_train_col)\n",
    "        new_test_matrix.append(new_test_col)\n",
    "        \n",
    "    # Second level learning model\n",
    "    new_train_matrix = np.array(new_train_matrix)\n",
    "    new_test_matrix = np.array(new_test_matrix)\n",
    "    new_train_matrix,new_test_matrix = new_train_matrix.T,new_test_matrix.T\n",
    "    \n",
    "    param_dict = {\n",
    "        'tree_method':'gpu_hist'\n",
    "    }\n",
    "#     layer2_model = XGBClassifier(silent=False,\n",
    "#             learning_rate=0.1,n_estimators=100,max_depth=3,min_child_weight=1,gamma=0,\n",
    "#             subsample=1,colsample_bytree=1,objective= 'binary:logistic',nthread=10,\n",
    "#             scale_pos_weight=1,seed=1337,**param_dict)\n",
    "    layer2_model = LGBMClassifier(\n",
    "            num_leaves=31,boosting_type='gbdt',max_depth=3,learning_rate=0.1,n_estimators=150,\n",
    "            subsample_for_bin=50000,objective='binary',min_split_gain=0.,min_child_weight=1e-3,\n",
    "            min_child_samples=20,subsample=1.,subsample_freq=1,\n",
    "            colsample_bytree=1.,reg_alpha=0.,reg_lambda=0.,n_jobs=12,silent=True)\n",
    "    layer2_model.fit(new_train_matrix, y)\n",
    "    pred_result = layer2_model.predict_proba(new_test_matrix)[:,1]\n",
    "    return pred_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM4\n",
      "LGBM4\n",
      "LGBM4\n",
      "LGBM4\n",
      "LGBM4\n",
      "vali_auc:0.827996843154\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM4\n",
      "LGBM4\n",
      "LGBM4\n",
      "LGBM4\n",
      "LGBM4\n",
      "vali_auc:0.831314843511\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM4\n",
      "LGBM4\n",
      "LGBM4\n",
      "LGBM4\n",
      "LGBM4\n",
      "vali_auc:0.830502519758\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM1\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM2\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM3\n",
      "LGBM4\n",
      "LGBM4\n",
      "LGBM4\n",
      "LGBM4\n",
      "LGBM4\n",
      "vali_auc:0.830111408145\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "RF\n",
      "LGBM1\n"
     ]
    }
   ],
   "source": [
    "# stacking交叉验证\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "X = pd.DataFrame(X).fillna('-1').values\n",
    "test = pd.DataFrame(test).fillna('-1').values\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_vali = X[train_index], X[test_index]\n",
    "    y_train, y_vali = y[train_index], y[test_index]\n",
    "    \n",
    "    model_l = [\n",
    "    'RF', \n",
    "    'LGBM1', \n",
    "    'LGBM2', \n",
    "    'LGBM3',\n",
    "    'LGBM4',\n",
    "    ]\n",
    "    resu = stacking(model_l,X_train,y_train,X_vali)\n",
    "    \n",
    "    vali_auc = metrics.roc_auc_score(y_vali,resu)\n",
    "    print (\"vali_auc:\"+str(vali_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking最终结果\n",
    "X_set = pd.DataFrame(X).fillna('-1').values\n",
    "test = pd.DataFrame(test).fillna('-1').values\n",
    "model_l = [\n",
    "    'RF', \n",
    "    'LGBM1', \n",
    "    'LGBM2', \n",
    "    'LGBM3',\n",
    "    'LGBM4',\n",
    "    ]\n",
    "resu = stacking(model_l,X,y,test)\n",
    "index = pd.DataFrame(data=np.arange(1, len(test)+1))\n",
    "pred_pandas=pd.DataFrame(data=resu)\n",
    "pred_pandas = pd.concat([index, pred_pandas], axis=1)\n",
    "pred_pandas.to_csv('./Stacking_1.csv', header=['Id', 'label'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 其他stacking 的基模型\n",
    "rf_X = pd.DataFrame(X).fillna('-1').values\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True, random_state=1377)\n",
    "RF_model = RandomForestClassifier(bootstrap=True,n_jobs=6,max_depth=12, random_state=1377,n_estimators=200)\n",
    "Ada_model = AdaBoostClassifier(random_state=1377,n_estimators=200)\n",
    "Bag_model = BaggingClassifier(n_estimators=200,random_state=1377,n_jobs=6)\n",
    "Extra_model = ExtraTreesClassifier(n_estimators=200,bootstrap=True,random_state=1377,n_jobs=6)\n",
    "Grad_model  = GradientBoostingClassifier(n_estimators=300, random_state=1377)\n",
    "OCSVM_model = svm.OneClassSVM(random_state=1377)\n",
    "SVC_model = svm.SVC(random_state=1377)\n",
    "SVR_model = svm.SVR()\n",
    "\n",
    "list_model = [\n",
    "#    'RF','Ada',\n",
    "#     'Extra','Grad','OCSVM','SVC',\n",
    "    'SVR'\n",
    "]\n",
    "\n",
    "for m in list_model:\n",
    "    for train_index, test_index in skf.split(rf_X, y):\n",
    "        X_train, X_vali = rf_X[train_index], rf_X[test_index]\n",
    "        y_train, y_vali = y[train_index], y[test_index]\n",
    "        if m == 'RF':\n",
    "            RF_model.fit(X_train, y_train)\n",
    "            y_vali_pred = RF_model.predict_proba(X_vali)[:,1]\n",
    "        elif m == 'Ada':\n",
    "            Ada_model.fit(X_train, y_train)\n",
    "            y_vali_pred = Ada_model.predict_proba(X_vali)[:,1]\n",
    "        elif m == 'Bag':\n",
    "            Bag_model.fit(X_train, y_train)\n",
    "            y_vali_pred = Bag_model.predict_proba(X_vali)[:,1]\n",
    "        elif m == 'Extra':\n",
    "            Extra_model.fit(X_train, y_train)\n",
    "            y_vali_pred = Extra_model.predict_proba(X_vali)[:,1]\n",
    "        elif m == 'Grad':\n",
    "            Grad_model.fit(X_train, y_train)\n",
    "            y_vali_pred = Grad_model.predict_proba(X_vali)[:,1]\n",
    "        elif m == 'OCSVM':\n",
    "            OCSVM_model.fit(X_train, y_train)\n",
    "            y_vali_pred = OCSVM_model.predict(X_vali)\n",
    "        elif m == 'SVC':\n",
    "            SVC_model.fit(X_train, y_train)\n",
    "            y_vali_pred = SVC_model.predict(X_vali)\n",
    "        elif m == 'SVR':\n",
    "            SVR_model.fit(X_train, y_train)\n",
    "            y_vali_pred = SVR_model.predict(X_vali)\n",
    "        vali_auc = metrics.roc_auc_score(y_vali,y_vali_pred)\n",
    "        print (\"model: \"+str(m)+\"\\t\"+\"vali_auc:\"+str(vali_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
